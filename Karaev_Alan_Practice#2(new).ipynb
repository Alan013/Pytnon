{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import io\n",
    "import requests\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm_notebook\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import math\n",
    "from math import log\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score, make_scorer\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "import sklearn.neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (8, 8)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание  2. Решающее дерево"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 [10 баллов]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте свой класс Решающее дерево (для задачи классификации и регрессии). Шаблон класса представлен ниже, однако дерево не обязательно реализовывать именно по такому шаблону, главное, чтобы у ваше класса был метод .fit() - по двумерной матрице объект-признак и одномерному вектору таргетов получает оптимальные предикаты и метод .predict() - по двумерной матрице объект-признак возвращает одномерный вектор предсказаний.\n",
    "\n",
    "Построение дерева должно осуществляться согласно базовому жадному алгоритму. Выбор лучшего разбиения необходимо производить по критерию, поданному в качестве аргумента в init (\"Gini\" или \"Entropy\" - для задачи классификации и \"Variance\" - для задачи регрессии). Критерий останова: все объекты в листе относятся к одному классу. Ответ в листе: класс объектов, находящихся в нем. Для категориальных признаков необходимо выполнить преобразование, описанное на [семинаре](https://github.com/esokolov/ml-course-msu/blob/master/ML16/lecture-notes/Sem04_trees.pdf) в разделе \"Учет категориальных признаков\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode:\n",
    "    def __init__(self, data, output):\n",
    "        self.data = data\n",
    "        self.children = {}\n",
    "        self.output = output\n",
    "        self.index = -1\n",
    "        \n",
    "    def add_child(self,feature_value,obj):\n",
    "        self.children[feature_value] = obj\n",
    "        \n",
    "        \n",
    "class DecisionTree:\n",
    "    def __init__(self):\n",
    "        self.__root = None\n",
    "\n",
    "    def __count_unique(self,Y):\n",
    "        d = {}\n",
    "        for i in Y:\n",
    "            if i not in d:\n",
    "                d[i]=1\n",
    "            else:\n",
    "                d[i]+=1\n",
    "        return d\n",
    "\n",
    "    def __entropy(self,Y):\n",
    "        freq_map = self.__count_unique(Y)\n",
    "        entropy_ = 0\n",
    "        total = len(Y)\n",
    "        for i in freq_map:\n",
    "            p = freq_map[i]/total\n",
    "            entropy_ += (-p)*math.log2(p)\n",
    "        return entropy_\n",
    "\n",
    "    def __entropy_index(self,X,Y,selected_feature):\n",
    "        info_orig = self.__entropy(Y) \n",
    "        info_f = 0  \n",
    "        split_info = 0\n",
    "        values = set(X[:,selected_feature])\n",
    "        df = pd.DataFrame(X)\n",
    "        df[df.shape[1]] = Y\n",
    "        initial_size = df.shape[0] \n",
    "        for i in values:\n",
    "            df1 = df[df[selected_feature] == i]\n",
    "            current_size = df1.shape[0]\n",
    "            info_f += (current_size/initial_size)*self.__entropy(df1[df1.shape[1]-1])\n",
    "            split_info += (-current_size/initial_size)*math.log2(current_size/initial_size)\n",
    "\n",
    "        if split_info == 0 :\n",
    "            return math.inf\n",
    "\n",
    "        info_gain = info_orig - info_f\n",
    "        entropy_index = info_gain / split_info\n",
    "        return entropy_index\n",
    "\n",
    "    def __gini_(self,Y):\n",
    "        freq_map = self.__count_unique(Y)\n",
    "        gini__ = 1\n",
    "        total = len(Y)\n",
    "        for i in freq_map:\n",
    "            p = freq_map[i]/total\n",
    "            gini__ -= p**2\n",
    "        return gini__\n",
    "\n",
    "    def __gini_index(self,X,Y,selected_feature):\n",
    "        gini_orig = self.__gini_(Y) \n",
    "        gini_split_f = 0 \n",
    "        values = set(X[:,selected_feature])\n",
    "        df = pd.DataFrame(X)\n",
    "        df[df.shape[1]] = Y\n",
    "        initial_size = df.shape[0] \n",
    "        for i in values:\n",
    "            df1 = df[df[selected_feature] == i]\n",
    "            current_size = df1.shape[0]\n",
    "            gini_split_f += (current_size/initial_size)*self.__gini_(df1[df1.shape[1]-1])\n",
    "\n",
    "        gini_index_ = gini_orig - gini_split_f\n",
    "        return gini_index_\n",
    "\n",
    "    \n",
    "    def __decision_tree(self,X,Y,features,level,metric,classes):\n",
    "\n",
    "        if len(set(Y)) == 1:\n",
    "            print(\"Уровень\",level)\n",
    "            for i in classes:\n",
    "                if i in Y:\n",
    "                    output = i\n",
    "                    print(\"Класс\",i,\"=\",len(Y))\n",
    "                else :\n",
    "                    print()\n",
    "\n",
    "            return TreeNode(None,output)\n",
    "\n",
    "        if len(features) == 0:\n",
    "            print(\"Уровень\",level)\n",
    "            freq_map = self.__count_unique(Y)\n",
    "            max_count = -math.inf\n",
    "            for i in classes:\n",
    "                if i not in freq_map:\n",
    "                    None\n",
    "                else :\n",
    "                    if freq_map[i] > max_count :\n",
    "                        output = i\n",
    "                        max_count = freq_map[i]\n",
    "                    print(\"Класс\",i,\"=\",freq_map[i])\n",
    "\n",
    "\n",
    "            print()\n",
    "            return TreeNode(None,output)\n",
    "\n",
    "    \n",
    "        max_gain = -math.inf\n",
    "        final_feature = None\n",
    "        for f in features :\n",
    "            if metric == \"entropy_index\":\n",
    "                current_gain = self.__entropy_index(X,Y,f)\n",
    "            elif metric ==\"gini_\":\n",
    "                current_gain = self.__gini_index(X,Y,f)\n",
    "\n",
    "            if current_gain > max_gain:\n",
    "                max_gain = current_gain\n",
    "                final_feature = f\n",
    "\n",
    "        freq_map = self.__count_unique(Y)\n",
    "        output = None\n",
    "        max_count = -math.inf\n",
    "\n",
    "           \n",
    "        unique_values = set(X[:,final_feature]) \n",
    "        df = pd.DataFrame(X)\n",
    "        df[df.shape[1]] = Y\n",
    "\n",
    "        current_node = TreeNode(final_feature,output)\n",
    "\n",
    "        \n",
    "        index  = features.index(final_feature)\n",
    "        features.remove(final_feature)\n",
    "        for i in unique_values:\n",
    "            df1 = df[df[final_feature] == i]\n",
    "            node = self.__decision_tree(df1.iloc[:,0:df1.shape[1]-1].values,df1.iloc[:,df1.shape[1]-1].values,features,level+1,metric,classes)\n",
    "            current_node.add_child(i,node)\n",
    "   \n",
    "        features.insert(index,final_feature)\n",
    "\n",
    "        return current_node\n",
    "    \n",
    "    def __predict_for(self,data,node):\n",
    "        if len(node.children) == 0 :\n",
    "            return node.output\n",
    "        \n",
    "        val = data[node.data]      \n",
    "        if val not in node.children :\n",
    "            return node.output\n",
    "        \n",
    "        return self.__predict_for(data,node.children[val])\n",
    "    \n",
    "\n",
    "    def predict(self,X):\n",
    "        Y = np.array([0 for i in range(len(X))])\n",
    "        for i in range(len(X)):\n",
    "            Y[i] = self.__predict_for(X[i],self.__root)\n",
    "        return Y\n",
    "    \n",
    "\n",
    "    def score(self,X,Y):\n",
    "        Y_pred = self.predict(X)\n",
    "        count = 0\n",
    "        for i in range(len(Y_pred)):\n",
    "            if Y_pred[i] == Y[i]:\n",
    "                count+=1\n",
    "        return count/len(Y_pred)\n",
    "\n",
    "    \n",
    "    def fit(self,X,Y,metric=\"entropy_index\"):\n",
    "\n",
    "        features = [i for i in range(len(X[0]))]\n",
    "        classes = set(Y)\n",
    "        level = 0\n",
    "        if metric != \"entropy_index\" :\n",
    "            if metric != \"gini_\":\n",
    "                metric=\"entropy_index\"  \n",
    "        self.__root = self.__decision_tree(X,Y,features,level,metric,classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 [3 балла]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируйте свое решающее дерево на датасете [mushrooms](https://archive.ics.uci.edu/ml/datasets/Mushroom). Вам нужно скачать таблицу agaricus-lepiota.data (из [Data Folder](https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/)), прочитать ее с помощью pandas, применить к каждому столбцу LabelEncoder (из sklearn), чтобы преобразовать строковые имена категорий в натуральные числа. Первый столбец - это целевая переменная (e-edible, p-poisonous) Мы будем измерять качество с помощью accuracy, так что нам не очень важно, что будет классом 1, а что - классом 0. Обучите решающее дерево на половине случайно выбранных объектов (признаки в датасете категориальные) и сделайте предсказания для оставшейся половины. Вычислите accuracy.\n",
    "\n",
    "У вас должно получиться значение accuracy, равное единице (или очень близкое к единице), и не очень глубокое дерево."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_M = pd.read_csv('agaricus-lepiota.data')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "data_M = data_M.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "y_M = data_M['p'].values\n",
    "X_M = data_M.drop(['p'], axis=1).values\n",
    "X_train_M, X_test_M, y_train_M, y_test_M = train_test_split(X_M,y_M,random_state=42,test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уровень 2\n",
      "Класс 0 = 204\n",
      "\n",
      "Уровень 2\n",
      "\n",
      "Класс 1 = 106\n",
      "Уровень 2\n",
      "\n",
      "Класс 1 = 1071\n",
      "Уровень 2\n",
      "Класс 0 = 180\n",
      "\n",
      "Уровень 2\n",
      "\n",
      "Класс 1 = 20\n",
      "Уровень 4\n",
      "Класс 0 = 24\n",
      "\n",
      "Уровень 4\n",
      "Класс 0 = 628\n",
      "\n",
      "Уровень 4\n",
      "Класс 0 = 656\n",
      "\n",
      "Уровень 4\n",
      "Класс 0 = 26\n",
      "\n",
      "Уровень 4\n",
      "\n",
      "Класс 1 = 33\n",
      "Уровень 4\n",
      "Класс 0 = 261\n",
      "\n",
      "Уровень 4\n",
      "Класс 0 = 23\n",
      "\n",
      "Уровень 7\n",
      "Класс 0 = 14\n",
      "\n",
      "Уровень 7\n",
      "\n",
      "Класс 1 = 16\n",
      "Уровень 10\n",
      "Класс 0 = 81\n",
      "\n",
      "Уровень 10\n",
      "\n",
      "Класс 1 = 6\n",
      "Уровень 7\n",
      "\n",
      "Класс 1 = 6\n",
      "Уровень 2\n",
      "\n",
      "Класс 1 = 118\n",
      "Уровень 2\n",
      "\n",
      "Класс 1 = 298\n",
      "Уровень 2\n",
      "\n",
      "Класс 1 = 290\n",
      "Accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "tree_M = DecisionTree()\n",
    "x = X_train_M\n",
    "y = y_train_M\n",
    "tree_M.fit(x,y,metric = 'gini_index')\n",
    "Y_pred = tree_M.predict(x)\n",
    "print(\"Accuracy :\",tree_M.score(x,y)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 [6 баллов]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите следующие наборы данных (напомним, что pandas умеет загружать файлы по url, в нашем случае это файл *.data), предварительно ознакомившись с описанием признаков и целевой переменной в каждом из них (она записаны в Data Folder, в файле *.names):\n",
    "\n",
    "<ul>\n",
    "    \n",
    "<li> \n",
    "\n",
    "[mushrooms](https://archive.ics.uci.edu/ml/datasets/Mushroom) (загрузили в предыдущем пункте, классы записаны в нулевом столбце) \n",
    "</li>\n",
    "\n",
    "<li> \n",
    "\n",
    "[tic-rac-toe](https://archive.ics.uci.edu/ml/datasets/Tic-Tac-Toe+Endgame) (классы записаны в последнем столбце) \n",
    "</li>\n",
    "\n",
    "<li>\n",
    "    \n",
    "[cars](https://archive.ics.uci.edu/ml/datasets/Car+Evaluation) (классы записаны в последнем столбце, считаем что unacc, acc - это класс 0, good, vgood - класс 1)\n",
    "</li>\n",
    "\n",
    "<li>\n",
    "    \n",
    "[nurcery](https://archive.ics.uci.edu/ml/datasets/Nursery) (классы записаны в последнем столбце, считаем, что not_recom и recom - класс 0, very_recom, priority, spec_prior - класс 1)\n",
    "</li>\n",
    "</ul>\n",
    "\n",
    "Закодируйте категориальные признаки, использовав LabelEncoder. С помощью cross_val_score (cv=10) оцените accuracy на каждом из этих наборов данных следующих алгоритмов:\n",
    "\n",
    "<ul>\n",
    "<li>DecisionTree, считающий все признаки вещественными</li>\n",
    "\n",
    "<li>DecisionTree, считающий все признаки категориальными</li>\n",
    "\n",
    "<li>DecisionTree, считающий все признаки вещественными + one-hot-encoding всех признаков</li>\n",
    "\n",
    "<li>DecisionTreeClassifier из sklearn</li>\n",
    "</ul>\n",
    "\n",
    "Запишите результат в pd.DataFrame (по строкам - наборы данных, по столбцам - алгоритмы).\n",
    "Рекомендации:\n",
    "\n",
    "Чтобы cross_val_score вычисляла точность, нужно передать scorer=make_scorer(accuracy_score), обе фукнции из sklearn.metrics.\n",
    "Если вам позволяет память (а она скорее всего позволяет), указывайте параметр sparse=False в OneHotEncoder (если вы, конечно, используете его). Иначе вам придется добиваться того, чтобы ваша реализация дерева умела работать с разреженными матрицами (что тоже, в целом, не очень сложно)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_1=\"https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\"\n",
    "url_2=\"https://archive.ics.uci.edu/ml/machine-learning-databases/tic-tac-toe/tic-tac-toe.data\"\n",
    "url_3=\"https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data\"\n",
    "url_4=\"https://archive.ics.uci.edu/ml/machine-learning-databases/nursery/nursery.data\"\n",
    "\n",
    "dat_mus=pd.read_csv(io.StringIO(requests.get(url_1).content.decode('utf-8')))\n",
    "dat_trt=pd.read_csv(io.StringIO(requests.get(url_2).content.decode('utf-8')))\n",
    "dat_car=pd.read_csv(io.StringIO(requests.get(url_3).content.decode('utf-8')))\n",
    "dat_nur=pd.read_csv(io.StringIO(requests.get(url_4).content.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_car.loc[dat_car.unacc == \"unacc\", 'unacc'] = 0\n",
    "dat_car.loc[dat_car.unacc == \"acc\", 'unacc'] = 0\n",
    "dat_car.loc[dat_car.unacc == \"good\", 'unacc'] = 1\n",
    "dat_car.loc[dat_car.unacc == \"vgood\", 'unacc'] = 1\n",
    "\n",
    "dat_nur.loc[dat_nur.recommend == \"recommend\", 'recommend'] = 0\n",
    "dat_nur.loc[dat_nur.recommend == \"not_recom\", 'recommend'] = 0\n",
    "dat_nur.loc[dat_nur.recommend == \"very_recom\", 'recommend'] = 1\n",
    "dat_nur.loc[dat_nur.recommend == \"priority\", 'recommend'] = 1\n",
    "dat_nur.loc[dat_nur.recommend == \"spec_prior\", 'recommend'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "dat_mus = dat_mus.apply(LabelEncoder().fit_transform)\n",
    "dat_trt = dat_trt.apply(LabelEncoder().fit_transform)\n",
    "dat_car = dat_car.apply(LabelEncoder().fit_transform)\n",
    "dat_nur = dat_nur.apply(LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9627160673579608"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scor = make_scorer(accuracy_score)\n",
    "dat_mus = dat_mus.astype('Float64')\n",
    "tre_mus = DecisionTreeClassifier(random_state = 2)\n",
    "y_mus = dat_mus['p'].values\n",
    "x_mus = dat_mus.drop(['p'], axis = 1).values\n",
    "scor_mus_sklearn = cross_val_score(tre_mus, x_mus, y_mus, cv=10, scoring = scor)\n",
    "scor_mus_sklearn.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7208906447820582"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tre_trt = DecisionTreeClassifier(random_state = 2)\n",
    "y_trt = dat_trt['positive'].values\n",
    "x_trt = dat_trt.drop(['positive'], axis = 1).values\n",
    "scor_trt_sklearn = cross_val_score(tre_trt, x_trt, y_trt, cv=10, scoring = scor)\n",
    "scor_trt_sklearn.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9409550551381118"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tre_car = DecisionTreeClassifier(random_state = 2)\n",
    "y_car = dat_car['unacc'].values\n",
    "x_car = dat_car.drop(['unacc'], axis = 1).values\n",
    "scor_car_sklearn = cross_val_score(tre_car, x_car, y_car, cv=10, scoring = scor)\n",
    "scor_car_sklearn.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998457385038598"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tre_nur = DecisionTreeClassifier(random_state = 2)\n",
    "y_nur = dat_nur['recommend'].values\n",
    "x_nur = dat_nur.drop(['recommend'], axis = 1).values\n",
    "scor_nur_sklearn = cross_val_score(tre_nur, x_nur, y_nur, cv=10, scoring = scor)\n",
    "scor_nur_sklearn.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Sklearn mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mushrooms</td>\n",
       "      <td>0.962716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tik-roc-tic</td>\n",
       "      <td>0.720891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cars</td>\n",
       "      <td>0.940955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nurcery</td>\n",
       "      <td>0.999846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Method  Sklearn mean\n",
       "0    Mushrooms      0.962716\n",
       "1  Tik-roc-tic      0.720891\n",
       "2         Cars      0.940955\n",
       "3      Nurcery      0.999846"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_sklearn = [['Mushrooms', scor_mus_sklearn.mean()], ['Tik-roc-tic', scor_trt_sklearn.mean()],\n",
    "                ['Cars', scor_car_sklearn.mean()],['Nurcery', scor_nur_sklearn.mean()]]\n",
    "pd.DataFrame(data=dat_sklearn, columns = ['Method','Sklearn mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_mus_int = dat_mus.astype('Int64')\n",
    "dat_trt_int = dat_trt.astype('Int64')\n",
    "dat_car_int = dat_car.astype('Int64')\n",
    "dat_nur_int = dat_nur.astype('Int64')\n",
    "\n",
    "One_Hot = OneHotEncoder(categorical_features = [0])\n",
    "x_mus_One_Hot = One_Hot.fit_transform(x_mus).toarray()\n",
    "x_trt_One_Hot = One_Hot.fit_transform(x_trt).toarray()\n",
    "x_car_One_Hot = One_Hot.fit_transform(x_car).toarray()\n",
    "x_nur_One_Hot = One_Hot.fit_transform(x_nur).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3. Композиция деревьев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 [3 балла]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите датасет [winequality-red.csv](https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv) в датафрейм. Последний столбец - целевая переменная (содержит классы).\n",
    "\n",
    "С помощью cross_val_score с cv=5 оцените качество (accuracy) следующих классификаторов:\n",
    "<ul>\n",
    "<li>DecisionTreeClassifier</li>\n",
    "<li>BaggingClassifier со 100 деревьями</li>\n",
    "<li>BaggingClassifier со 100 деревьями; каждое дерево обучается только по половине случайно выбранных признаков (см. параметры метода)</li>\n",
    "<li>RandomForestClassifier со 100 деревьями</li>\n",
    "</ul>\n",
    "Значение получается шумное, но в целом у вас должно получиться, что качество возрастает с каждым следующим алгоритмом. Этот пример демонстрирует, что RandomForest - это более сложный алгоритм, чем бэггинг и бэггинг со случайными подпространствами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = pd.read_csv('winequality-red.csv', sep = ';')\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.48 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "tree_wine = DecisionTreeClassifier(random_state = 1)\n",
    "a_wine = wine['quality'].values\n",
    "b_wine = wine.drop(['quality'], axis = 1).values\n",
    "scor = cross_val_score(tree_wine, b_wine, a_wine, cv=5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scor.mean(), scor.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.56 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "Bag = BaggingClassifier(base_estimator = DecisionTreeClassifier(), n_estimators = 100, random_state = 4)\n",
    "scor_2 = cross_val_score(Bag, b_wine, a_wine, cv=5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scor_2.mean(), scor_2.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.55 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "Bag_2 = BaggingClassifier(base_estimator = DecisionTreeClassifier(), n_estimators = 100, random_state = 3, max_features = 0.5)\n",
    "scor_3 = cross_val_score(Bag_2, b_wine, a_wine, cv=5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scor_3.mean(), scor_3.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.56 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "Ran = RandomForestClassifier(n_estimators = 100, random_state = 3)\n",
    "scor_4 = cross_val_score(Ran, b_wine, a_wine, cv=5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scor_4.mean(), scor_4.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Accuracy Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.475287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.561090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.552210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.564185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Method  Accuracy Mean\n",
       "0  DecisionTreeClassifier       0.475287\n",
       "1       BaggingClassifier       0.561090\n",
       "2       BaggingClassifier       0.552210\n",
       "3  RandomForestClassifier       0.564185"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine0 = [['DecisionTreeClassifier', scor.mean()], ['BaggingClassifier', scor_2.mean()], \n",
    "             ['BaggingClassifier', scor_3.mean()], \n",
    "             ['RandomForestClassifier', scor_4.mean()]]\n",
    "pd.DataFrame(data=wine0, columns = ['Method', 'Accuracy Mean'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
